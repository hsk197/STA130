{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976bcded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0\n",
       "sepal_width     0\n",
       "petal_length    0\n",
       "petal_width     0\n",
       "species         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STA130HW01\n",
    "#Heesu Kim 1002654978\n",
    "#Due Sept 12, 2024\n",
    "\n",
    "#1\n",
    "##Testing code with dataset that has no missing value\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af7a92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing code with dataset that has some missing value\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f80ba14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset:\n",
      "Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
      "       'total_bedrooms', 'population', 'households', 'median_income',\n",
      "       'median_house_value', 'ocean_proximity'],\n",
      "      dtype='object')\n",
      "\n",
      "Number of rows and columns:\n",
      "(20640, 10)\n",
      "\n",
      "First few rows of the dataset:\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n"
     ]
    }
   ],
   "source": [
    "#2\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "print(\"\\nNumber of rows and columns:\")\n",
    "print(df.shape)\n",
    "\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "#Observation is a single entry or data point in dataset.\n",
    "#Variable is a characteristic or attribute that can be measured or identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88635890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude             float64\n",
      "latitude              float64\n",
      "housing_median_age    float64\n",
      "total_rooms           float64\n",
      "total_bedrooms        float64\n",
      "population            float64\n",
      "households            float64\n",
      "median_income         float64\n",
      "median_house_value    float64\n",
      "ocean_proximity        object\n",
      "dtype: object\n",
      "          longitude      latitude  housing_median_age   total_rooms  \\\n",
      "count  20640.000000  20640.000000        20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861           28.639486   2635.763081   \n",
      "std        2.003532      2.135952           12.585558   2181.615252   \n",
      "min     -124.350000     32.540000            1.000000      2.000000   \n",
      "25%     -121.800000     33.930000           18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000           29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000           37.000000   3148.000000   \n",
      "max     -114.310000     41.950000           52.000000  39320.000000   \n",
      "\n",
      "       total_bedrooms    population    households  median_income  \\\n",
      "count    20433.000000  20640.000000  20640.000000   20640.000000   \n",
      "mean       537.870553   1425.476744    499.539680       3.870671   \n",
      "std        421.385070   1132.462122    382.329753       1.899822   \n",
      "min          1.000000      3.000000      1.000000       0.499900   \n",
      "25%        296.000000    787.000000    280.000000       2.563400   \n",
      "50%        435.000000   1166.000000    409.000000       3.534800   \n",
      "75%        647.000000   1725.000000    605.000000       4.743250   \n",
      "max       6445.000000  35682.000000   6082.000000      15.000100   \n",
      "\n",
      "       median_house_value  \n",
      "count        20640.000000  \n",
      "mean        206855.816909  \n",
      "std         115395.615874  \n",
      "min          14999.000000  \n",
      "25%         119600.000000  \n",
      "50%         179700.000000  \n",
      "75%         264725.000000  \n",
      "max         500001.000000  \n",
      "       ocean_proximity\n",
      "count            20640\n",
      "unique               5\n",
      "top          <1H OCEAN\n",
      "freq              9136\n",
      "ocean_proximity    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "#overview of datatypes and column\n",
    "print(df.dtypes)\n",
    "\n",
    "#descriptive statistics for numerical columns\n",
    "numerical_summary = df.describe()\n",
    "print(numerical_summary)\n",
    "\n",
    "#descriptive statistics for categorical columns\n",
    "categorical_summary = df.describe(include=['object'])\n",
    "print(categorical_summary)\n",
    "\n",
    "#count unique values for categorical columns\n",
    "unique_values = df.select_dtypes(include=['object']).nunique()\n",
    "print(unique_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04ebbc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n",
      "          survived      pclass   sex         age       sibsp       parch  \\\n",
      "count   891.000000  891.000000   891  714.000000  891.000000  891.000000   \n",
      "unique         NaN         NaN     2         NaN         NaN         NaN   \n",
      "top            NaN         NaN  male         NaN         NaN         NaN   \n",
      "freq           NaN         NaN   577         NaN         NaN         NaN   \n",
      "mean      0.383838    2.308642   NaN   29.699118    0.523008    0.381594   \n",
      "std       0.486592    0.836071   NaN   14.526497    1.102743    0.806057   \n",
      "min       0.000000    1.000000   NaN    0.420000    0.000000    0.000000   \n",
      "25%       0.000000    2.000000   NaN   20.125000    0.000000    0.000000   \n",
      "50%       0.000000    3.000000   NaN   28.000000    0.000000    0.000000   \n",
      "75%       1.000000    3.000000   NaN   38.000000    1.000000    0.000000   \n",
      "max       1.000000    3.000000   NaN   80.000000    8.000000    6.000000   \n",
      "\n",
      "              fare embarked  class  who adult_male deck  embark_town alive  \\\n",
      "count   891.000000      889    891  891        891  203          889   891   \n",
      "unique         NaN        3      3    3          2    7            3     2   \n",
      "top            NaN        S  Third  man       True    C  Southampton    no   \n",
      "freq           NaN      644    491  537        537   59          644   549   \n",
      "mean     32.204208      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "std      49.693429      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "min       0.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "25%       7.910400      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "50%      14.454200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "75%      31.000000      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "max     512.329200      NaN    NaN  NaN        NaN  NaN          NaN   NaN   \n",
      "\n",
      "       alone  \n",
      "count    891  \n",
      "unique     2  \n",
      "top     True  \n",
      "freq     537  \n",
      "mean     NaN  \n",
      "std      NaN  \n",
      "min      NaN  \n",
      "25%      NaN  \n",
      "50%      NaN  \n",
      "75%      NaN  \n",
      "max      NaN  \n"
     ]
    }
   ],
   "source": [
    "#4\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261d1882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data preview:\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "Data preview after dropping rows with missing values:\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "1             2         1       1   \n",
      "3             4         1       1   \n",
      "6             7         0       1   \n",
      "10           11         1       3   \n",
      "11           12         1       1   \n",
      "\n",
      "                                                 Name     Sex   Age  SibSp  \\\n",
      "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
      "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
      "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
      "\n",
      "    Parch    Ticket     Fare Cabin Embarked  \n",
      "1       0  PC 17599  71.2833   C85        C  \n",
      "3       0    113803  53.1000  C123        S  \n",
      "6       0     17463  51.8625   E46        S  \n",
      "10      1   PP 9549  16.7000    G6        S  \n",
      "11      0    113783  26.5500  C103        S  \n",
      "\n",
      "Original dataset shape: (891, 12)\n",
      "Cleaned dataset shape: (183, 12)\n",
      "Initial data preview:\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Missing values per column:\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n",
      "\n",
      "Data preview after deleting the 'total_bedrooms' column:\n",
      "   longitude  latitude  housing_median_age  total_rooms  population  \\\n",
      "0    -122.23     37.88                41.0        880.0       322.0   \n",
      "1    -122.22     37.86                21.0       7099.0      2401.0   \n",
      "2    -122.24     37.85                52.0       1467.0       496.0   \n",
      "3    -122.25     37.85                52.0       1274.0       558.0   \n",
      "4    -122.25     37.85                52.0       1627.0       565.0   \n",
      "\n",
      "   households  median_income  median_house_value ocean_proximity  \n",
      "0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Original dataset shape: (20640, 9)\n",
      "Shape after deleting 'total_bedrooms' column: (20640, 9)\n"
     ]
    }
   ],
   "source": [
    "#5\n",
    "\n",
    "#Atribute\n",
    "\n",
    "#Atribute is a characteristic or property of an object.\n",
    "#It doesn't perform an action, but holds the data of the object.\n",
    "#It is accessed without parantheses.\n",
    "\n",
    "#Method\n",
    "\n",
    "#Method is a function associated with the object.\n",
    "#It performs action when its ran.\n",
    "#It is accessed with parantheses.\n",
    "\n",
    "#6\n",
    "#1) Count\n",
    "#It is the number of non-missing values in the dataset for each variable, \n",
    "#and its used to show how many valid entries there are for each column, helping identify missing data.\n",
    "\n",
    "#2) Mean\n",
    "#It is the arithmetic average of the data points. \n",
    "#It is calculated as the sum of all values divided by the number of values.\n",
    "#It is used to provide a measure central tendancy\n",
    "\n",
    "#3) std\n",
    "#It is a measure of how spread out the values are from the mean. \n",
    "#It quantifies the amount of variation or dispersion in a dataset.\n",
    "#It is tells that a small standard deviation indicates that the values are close to the mean, \n",
    "#while a large standard deviation indicates that they are spread out over a wider range.\n",
    "\n",
    "#4) min\n",
    "#It is the smallest value in the dataset for each variable.\n",
    "#It is used to identifies the lower boundary of the data distribution.\n",
    "\n",
    "#5) 25% (or Q1)\n",
    "#It is the value below which 25% of the data falls. It represents the first quartile.\n",
    "#It is used to help understand the lower tail of the distribution.\n",
    "\n",
    "#6) 50% (or Q2)\n",
    "#It is the middle value of the dataset, where half of the data is smaller and half is larger. \n",
    "#This is also the median.\n",
    "#It shows measure of central tendency, less affected by outliers than the mean.\n",
    "\n",
    "#7) 75% (or Q3)\n",
    "#It is the value below which 75% of the data falls.\n",
    "#It is used to provide insight into the upper tail of the distribution.\n",
    "\n",
    "#8) max\n",
    "#It is the largest value in the dataset for each variable.\n",
    "#It is used to identify the upper boundary of the data distribution.\n",
    "\n",
    "#7\n",
    "\n",
    "#1)\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset to see the initial data\n",
    "print(\"Initial data preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Drop rows with missing values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display the cleaned dataset (first few rows)\n",
    "print(\"\\nData preview after dropping rows with missing values:\")\n",
    "print(df_cleaned.head())\n",
    "\n",
    "# Show the shape of the dataset before and after cleaning\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "print(f\"Cleaned dataset shape: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "485e594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial data preview:\n",
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Missing values per column:\n",
      "longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n",
      "\n",
      "Data preview after deleting the 'total_bedrooms' column:\n",
      "   longitude  latitude  housing_median_age  total_rooms  population  \\\n",
      "0    -122.23     37.88                41.0        880.0       322.0   \n",
      "1    -122.22     37.86                21.0       7099.0      2401.0   \n",
      "2    -122.24     37.85                52.0       1467.0       496.0   \n",
      "3    -122.25     37.85                52.0       1274.0       558.0   \n",
      "4    -122.25     37.85                52.0       1627.0       565.0   \n",
      "\n",
      "   households  median_income  median_house_value ocean_proximity  \n",
      "0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       259.0         3.8462            342200.0        NEAR BAY  \n",
      "\n",
      "Original dataset shape: (20640, 9)\n",
      "Shape after deleting 'total_bedrooms' column: (20640, 9)\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#2)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the housing dataset from the provided URL\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataset to see the initial data\n",
    "print(\"Initial data preview:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values by column\n",
    "missing_data = df.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Identify a column with a high number of missing values and delete it (e.g., if it existed in this dataset)\n",
    "if 'total_bedrooms' in df.columns:  # 'total_bedrooms' may have missing values in the housing dataset\n",
    "    del df['total_bedrooms']  # Deleting a column with many missing values\n",
    "\n",
    "# Display the dataframe after deleting the column\n",
    "print(\"\\nData preview after deleting the 'total_bedrooms' column:\")\n",
    "print(df.head())\n",
    "\n",
    "# Show the shape of the dataset before and after removing the column\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "print(f\"Shape after deleting 'total_bedrooms' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2f2e38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape of the dataset: (20640, 10)\n",
      "Missing values before cleaning:\n",
      " longitude               0\n",
      "latitude                0\n",
      "housing_median_age      0\n",
      "total_rooms             0\n",
      "total_bedrooms        207\n",
      "population              0\n",
      "households              0\n",
      "median_income           0\n",
      "median_house_value      0\n",
      "ocean_proximity         0\n",
      "dtype: int64\n",
      "\n",
      "Final shape of the dataset after cleaning: (20640, 9)\n",
      "Missing values after cleaning:\n",
      " longitude             0\n",
      "latitude              0\n",
      "housing_median_age    0\n",
      "total_rooms           0\n",
      "population            0\n",
      "households            0\n",
      "median_income         0\n",
      "median_house_value    0\n",
      "ocean_proximity       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#7\n",
    "#3)\n",
    "#Removing column with del df[‘col’] first ensures avoiding to delete the entire rows that might be useful. \n",
    "#Removing columns with high amount of missing data reduces the amount of data that needs to be processed when deleting rows.\n",
    "#Without removing colums with high missing data, df.dropna() could reduce significant amount of the data\n",
    "\n",
    "#7\n",
    "#4)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display initial data info\n",
    "print(\"Initial shape of the dataset:\", df.shape)\n",
    "print(\"Missing values before cleaning:\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 1: Remove a column with significant missing values\n",
    "# In this dataset, let's assume 'total_bedrooms' has a high number of missing values\n",
    "if 'total_bedrooms' in df.columns:\n",
    "    del df['total_bedrooms']\n",
    "\n",
    "# Step 2: Drop rows with missing values in the remaining columns\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "# Display final data info\n",
    "print(\"\\nFinal shape of the dataset after cleaning:\", df_cleaned.shape)\n",
    "print(\"Missing values after cleaning:\\n\", df_cleaned.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d519f123",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: fare, dtype: float64\n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "pclass                                                                     \n",
      "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "# 1)\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Print the column names to verify the presence of expected columns\n",
    "print(titanic_df.columns)\n",
    "\n",
    "# Perform a descriptive statistical analysis on a column, e.g., 'Fare'\n",
    "print(titanic_df['fare'].describe())\n",
    "\n",
    "# If 'Pclass' is present, perform groupby operation\n",
    "if 'pclass' in titanic_df.columns:\n",
    "    fare_description_by_class = titanic_df.groupby('pclass')['fare'].describe()\n",
    "    print(fare_description_by_class)\n",
    "else:\n",
    "    print(\"Column 'pclass' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bce4628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: fare, dtype: float64\n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "pclass                                                                     \n",
      "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: fare, dtype: float64\n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "pclass                                                                     \n",
      "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "#8\n",
    "\n",
    "#2)\n",
    "#df.describe() provides summary statistics for all numerical columns across the entire dataset. \n",
    "#Count here shows the number of non-missing values for each column in the whole DataFrame. \n",
    "#If some rows are missing values in any column, the count will reflect the total number of available data points,\n",
    "#indicating the overall completeness of the data.\n",
    "\n",
    "#df.groupby(\"col1\")[\"col2\"].describe() first splits the data into groups based on unique values of col1. \n",
    "#Each group is then analyzed separately, and describe() is applied to col2 within these groups. \n",
    "#Count shows the number of non-missing values for col2 within each subgroup defined by col1.\n",
    "\n",
    "#3)\n",
    "#all errors for this question is fixed and I am submitting chatlog to present the effort made to this question.\n",
    "\n",
    "\n",
    "\n",
    "#A) working with chatbot is relatively easier.\n",
    "import pandas as pd\n",
    "\n",
    "#---------------------------------------------------------------------------\n",
    "#NameError                                 Traceback (most recent call last)\n",
    "#Cell In[2], line 2\n",
    "#      1 url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
    "#----> 2 df = pd.read_csv(url)\n",
    "#      3 df.isna().sum()\n",
    "\n",
    "#NameError: name 'pd' is not defined\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "\n",
    "#B)It is relatively easier to work with chatbot\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "#---------------------------------------------------------------------------\n",
    "#FileNotFoundError                         Traceback (most recent call last)\n",
    "#Cell In[10], line 3\n",
    "#      1 import pandas as pd\n",
    "#      2 url = \"tatanic.csv\"\n",
    "#----> 3 df = pd.read_csv(url)\n",
    "#      4 df.isna().sum()\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#C)It was relatively easeir to work with chatbot.\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "df = pd.read_csv(url)\n",
    "#ERROR ENCOUNTERED WHEN USED Df instead of df\n",
    "#---------------------------------------------------------------------------\n",
    "#NameError                                 Traceback (most recent call last)\n",
    "#Cell In[9], line 4\n",
    "#      2 url = \"https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.csv\"\n",
    "#      3 Df = pd.read_csv(url)\n",
    "#----> 4 df.isna().sum()\n",
    "#\n",
    "#NameError: name 'df' is not defined\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "\n",
    "#D)It is relatively easier to google search it.\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\"\n",
    "df = pd.read_csv(url)\n",
    "# Cell In[6], line 3\n",
    "#    df = pd.read_csv(url\n",
    "#SyntaxError: '(' was never closed\n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "\n",
    "\n",
    "#E)It is relatively easeir to work with google.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Print the column names to verify the presence of expected columns\n",
    "print(titanic_df.columns)\n",
    "\n",
    "# Perform a descriptive statistical analysis on a column, e.g., 'Fare'\n",
    "print(titanic_df['fare'].describe())\n",
    "\n",
    "# If 'Pclass' is present, perform groupby operation\n",
    "if 'pclass' in titanic_df.columns:\n",
    "    fare_description_by_class = titanic_df.groupby('pclass')['fare'].describe()\n",
    "    print(fare_description_by_class)\n",
    "#ERROR ENCOUNTERED WHEN USED ['Fare'] instead of ['fare']  \n",
    "#    ---------------------------------------------------------------------------\n",
    "#KeyError                                  Traceback (most recent call last)\n",
    "#Cell In[8], line 18\n",
    "#     16 # If 'Pclass' is present, perform groupby operation\n",
    "#     17 if 'pclass' in titanic_df.columns:\n",
    "#---> 18     fare_description_by_class = titanic_df.groupby('pclass')['Fare'].describe()\n",
    "#     19     print(fare_description_by_class)\n",
    "#     20 else:\n",
    "#\n",
    "#File /opt/conda/lib/python3.11/site-packages/pandas/core/groupby/generic.py:1964, in DataFrameGroupBy.__getitem__(self, key)\n",
    "#   1957 if isinstance(key, tuple) and len(key) > 1:\n",
    "#   1958     # if len == 1, then it becomes a SeriesGroupBy and this is actually\n",
    "#   1959     # valid syntax, so don't raise\n",
    "#   1960     raise ValueError(\n",
    "#   1961         \"Cannot subset columns with a tuple with more than one element. \"\n",
    "#   1962         \"Use a list instead.\"\n",
    "#   1963     )\n",
    "#-> 1964 return super().__getitem__(key)\n",
    "#\n",
    "#File /opt/conda/lib/python3.11/site-packages/pandas/core/base.py:244, in SelectionMixin.__getitem__(self, key)\n",
    "#    242 else:\n",
    "#    243     if key not in self.obj:\n",
    "#--> 244         raise KeyError(f\"Column not found: {key}\")\n",
    "#    245     ndim = self.obj[key].ndim\n",
    "#    246     return self._gotitem(key, ndim=ndim)\n",
    "#\n",
    "#KeyError: 'Column not found: Fare'\n",
    "\n",
    "else:\n",
    "    print(\"Column 'pclass' does not exist in the DataFrame.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#F)It is relatively easier to work with chatbot.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Print the column names to verify the presence of expected columns\n",
    "print(titanic_df.columns)\n",
    "\n",
    "# Perform a descriptive statistical analysis on a column, e.g., 'Fare'\n",
    "print(titanic_df['fare'].describe())\n",
    "# ERROR ENCOUNTERED WITH MISSPELLING Fare INSTEAD of fare\n",
    "#KeyError                                  Traceback (most recent call last)\n",
    "#File /opt/conda/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790, in Index.get_loc(self, key)\n",
    "#   3789 try:\n",
    "#-> 3790     return self._engine.get_loc(casted_key)\n",
    "#   3791 except KeyError as err:\n",
    "\n",
    "#File index.pyx:152, in pandas._libs.index.IndexEngine.get_loc()\n",
    "\n",
    "#File index.pyx:181, in pandas._libs.index.IndexEngine.get_loc()\n",
    "\n",
    "#File pandas/_libs/hashtable_class_helper.pxi:7080, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n",
    "\n",
    "#File pandas/_libs/hashtable_class_helper.pxi:7088, in pandas._libs.hashtable.PyObjectHashTable.get_item()\n",
    "\n",
    "#KeyError: 'Fare'\n",
    "\n",
    "# If 'Pclass' is present, perform groupby operation\n",
    "if 'pclass' in titanic_df.columns:\n",
    "    fare_description_by_class = titanic_df.groupby('pclass')['fare'].describe()\n",
    "    print(fare_description_by_class)\n",
    "else:\n",
    "    print(\"Column 'pclass' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bac3e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
      "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
      "       'alive', 'alone'],\n",
      "      dtype='object')\n",
      "count    891.000000\n",
      "mean      32.204208\n",
      "std       49.693429\n",
      "min        0.000000\n",
      "25%        7.910400\n",
      "50%       14.454200\n",
      "75%       31.000000\n",
      "max      512.329200\n",
      "Name: fare, dtype: float64\n",
      "        count       mean        std  min       25%      50%   75%       max\n",
      "pclass                                                                     \n",
      "1       216.0  84.154687  78.380373  0.0  30.92395  60.2875  93.5  512.3292\n",
      "2       184.0  20.662183  13.417399  0.0  13.00000  14.2500  26.0   73.5000\n",
      "3       491.0  13.675550  11.778142  0.0   7.75000   8.0500  15.5   69.5500\n"
     ]
    }
   ],
   "source": [
    "#G) It is relatively easier to work with chat.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset from the URL\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(titanic_df.head())\n",
    "\n",
    "# Print the column names to verify the presence of expected columns\n",
    "print(titanic_df.columns)\n",
    "\n",
    "# Perform a descriptive statistical analysis on a column, e.g., 'Fare'\n",
    "print(titanic_df['fare'].describe())\n",
    "\n",
    "#ERROR ENCOUNTERED WHEN USED [fare] instead of ['fare']\n",
    "#---------------------------------------------------------------------------\n",
    "#NameError                                 Traceback (most recent call last)\n",
    "#Cell In[7], line 14\n",
    "#     11 print(titanic_df.columns)\n",
    "#     13 # Perform a descriptive statistical analysis on a column, e.g., 'Fare'\n",
    "#---> 14 print(titanic_df[fare].describe())\n",
    "#     16 # If 'Pclass' is present, perform groupby operation\n",
    "#     17 if 'pclass' in titanic_df.columns:\n",
    "#\n",
    "#NameError: name 'fare' is not defined\n",
    "\n",
    "# If 'Pclass' is present, perform groupby operation\n",
    "if 'pclass' in titanic_df.columns:\n",
    "    fare_description_by_class = titanic_df.groupby('pclass')['fare'].describe()\n",
    "    print(fare_description_by_class)\n",
    "else:\n",
    "    print(\"Column 'pclass' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6192474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9\n",
    "# YES I HAVE.\n",
    "\n",
    "#CHATLOGS\n",
    "\n",
    "#https://chatgpt.com/share/66e3a1b0-db84-800e-98bc-ee74a3ed4b47\n",
    "#https://chatgpt.com/share/66e3a240-407c-800e-832a-513b36512923\n",
    "#https://chatgpt.com/share/66e3a285-9c9c-800e-b264-f43caa90ffff\n",
    "#https://chatgpt.com/share/66e3a2a6-db34-800e-85ba-ffc1d4a72776\n",
    "#https://chatgpt.com/share/66e3a2b7-bf40-800e-882b-335db1df3d46\n",
    "#https://chatgpt.com/share/66e3a2cd-dddc-800e-b75c-9a5c5a162c6a\n",
    "#https://chatgpt.com/share/66e3a2e0-e51c-800e-805b-d9866dcc5238"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
